{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2b0eb69-a3e6-4403-938e-c19dda92fa86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat,lit,upper,col,max,avg,dense_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4823a477-b006-4daa-8e97-1a2cdc43f1f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>dept</th><th>salary</th><th>joining_date</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>HR</td><td>3000</td><td>2021-01-10</td></tr><tr><td>2</td><td>Bob</td><td>IT</td><td>4000</td><td>2021-02-15</td></tr><tr><td>3</td><td>Charlie</td><td>IT</td><td>5000</td><td>2021-03-01</td></tr><tr><td>4</td><td>David</td><td>Finance</td><td>6000</td><td>2021-04-12</td></tr><tr><td>5</td><td>Eva</td><td>Finance</td><td>3500</td><td>2021-05-20</td></tr><tr><td>6</td><td>Frank</td><td>HR</td><td>2800</td><td>2021-06-10</td></tr><tr><td>7</td><td>Grace</td><td>IT</td><td>4500</td><td>2021-07-30</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alice",
         "HR",
         3000,
         "2021-01-10"
        ],
        [
         2,
         "Bob",
         "IT",
         4000,
         "2021-02-15"
        ],
        [
         3,
         "Charlie",
         "IT",
         5000,
         "2021-03-01"
        ],
        [
         4,
         "David",
         "Finance",
         6000,
         "2021-04-12"
        ],
        [
         5,
         "Eva",
         "Finance",
         3500,
         "2021-05-20"
        ],
        [
         6,
         "Frank",
         "HR",
         2800,
         "2021-06-10"
        ],
        [
         7,
         "Grace",
         "IT",
         4500,
         "2021-07-30"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "dept",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "joining_date",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function --> Create SparkSESSION\n",
    "def create_session():\n",
    "    spark_ses = SparkSession.builder\\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"create DataFrame\") \\\n",
    "        .getOrCreate()\n",
    "    return spark_ses\n",
    "\n",
    "# def create_df(spark,data,schema):\n",
    "#     df1 = spark.createDataFrame(data,schema)\n",
    "#     return df1\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "\n",
    "    spark = create_session()\n",
    "    input_data = [\n",
    "   (1, \"Alice\", \"HR\", 3000, \"2021-01-10\"),\n",
    "   (2, \"Bob\", \"IT\", 4000, \"2021-02-15\"),\n",
    "   (3, \"Charlie\", \"IT\", 5000, \"2021-03-01\"),\n",
    "   (4, \"David\", \"Finance\", 6000, \"2021-04-12\"),\n",
    "   (5, \"Eva\", \"Finance\", 3500, \"2021-05-20\"),\n",
    "   (6, \"Frank\", \"HR\", 2800, \"2021-06-10\"),\n",
    "   (7, \"Grace\", \"IT\", 4500, \"2021-07-30\"),]\n",
    "    schema = [\"id\", \"name\", \"dept\", \"salary\", \"joining_date\"]\n",
    "\n",
    "    df = spark.createDataFrame(input_data,schema)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "639d8d1d-ef5e-46f9-ab90-cd3ddfdd8fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+------+------------+--------------------+\n| id|   name|   dept|salary|joining_date|employee_designation|\n+---+-------+-------+------+------------+--------------------+\n|  1|  Alice|     HR|  3000|  2021-01-10|            Alice,HR|\n|  2|    Bob|     IT|  4000|  2021-02-15|              Bob,IT|\n|  3|Charlie|     IT|  5000|  2021-03-01|          Charlie,IT|\n|  4|  David|Finance|  6000|  2021-04-12|       David,Finance|\n|  5|    Eva|Finance|  3500|  2021-05-20|         Eva,Finance|\n|  6|  Frank|     HR|  2800|  2021-06-10|            Frank,HR|\n|  7|  Grace|     IT|  4500|  2021-07-30|            Grace,IT|\n+---+-------+-------+------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Concatenate name and department into a single column.\n",
    "\n",
    "new_df= df.withColumn(\"employee_designation\", concat(col(\"name\"), lit(\",\"), col(\"dept\")))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d84fb8dc-0607-4a25-9ce9-7c7eff6a1281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+------+------------+--------------+\n| id|   name|   dept|salary|joining_date|upper_employee|\n+---+-------+-------+------+------------+--------------+\n|  1|  Alice|     HR|  3000|  2021-01-10|         ALICE|\n|  2|    Bob|     IT|  4000|  2021-02-15|           BOB|\n|  3|Charlie|     IT|  5000|  2021-03-01|       CHARLIE|\n|  4|  David|Finance|  6000|  2021-04-12|         DAVID|\n|  5|    Eva|Finance|  3500|  2021-05-20|           EVA|\n|  6|  Frank|     HR|  2800|  2021-06-10|         FRANK|\n|  7|  Grace|     IT|  4500|  2021-07-30|         GRACE|\n+---+-------+-------+------+------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Convert all employee names to uppercase.\n",
    "upper_employee = df.withColumn(\"upper_employee\", upper(col(\"name\")))\n",
    "upper_employee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "426a687a-e85f-4261-95cf-efc473e6a8d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+------+------------+\n| id| name|dept|salary|joining_date|\n+---+-----+----+------+------------+\n|  1|Alice|  HR|  3000|  2021-01-10|\n+---+-----+----+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find employees whose name starts with “A”.\n",
    "df.filter(col(\"name\").startswith(\"A\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0673b38-98bd-4132-8eea-787769504ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+------+------------+\n| id|   name|   dept|salary|joining_date|\n+---+-------+-------+------+------------+\n|  1|  Alice|     HR|  3000|  2021-01-10|\n|  3|Charlie|     IT|  5000|  2021-03-01|\n|  4|  David|Finance|  6000|  2021-04-12|\n+---+-------+-------+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#  Find the highest salary in each department.\n",
    "max_salary = df.groupby(\"dept\").agg(max(\"salary\").alias(\"highest_Salary\"))\n",
    "result_df = df.join(max_salary, (df.dept == max_salary.dept) & (df.salary == max_salary.highest_Salary), \"inner\") \\\n",
    "              .select(df[\"*\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c813137-4758-4a1d-80c5-3b2c1a439e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of employees joined after marc 2021:5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count how many employees joined after March 2021.\n",
    "count_2021= df.filter(df.joining_date > \"2021-03\").count()\n",
    "print(f'no.of employees joined after marc 2021:{count_2021}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3556267c-c74e-44e9-bafd-cbe20b15699e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+------+------------+----------+\n| id|   name|   dept|salary|joining_date|avg_salary|\n+---+-------+-------+------+------------+----------+\n|  4|  David|Finance|  6000|  2021-04-12|    4750.0|\n|  1|  Alice|     HR|  3000|  2021-01-10|    2900.0|\n|  3|Charlie|     IT|  5000|  2021-03-01|    4500.0|\n+---+-------+-------+------+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Show employees earning more than department average.\n",
    "from pyspark.sql.window import Window\n",
    "window_spec = Window.partitionBy(\"dept\")\n",
    "df_with_avg = df.withColumn(\"avg_salary\", avg(\"salary\").over(window_spec))\n",
    "earn_more = df_with_avg.filter(col(\"salary\") > col(\"avg_salary\"))\n",
    "earn_more.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b69ff3-1208-43f2-abca-4466f9d81280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+------+------------+------------+\n| id|   name|   dept|salary|joining_date|bonus_salary|\n+---+-------+-------+------+------------+------------+\n|  1|  Alice|     HR|  3000|  2021-01-10|       300.0|\n|  2|    Bob|     IT|  4000|  2021-02-15|       400.0|\n|  3|Charlie|     IT|  5000|  2021-03-01|       500.0|\n|  4|  David|Finance|  6000|  2021-04-12|       600.0|\n|  5|    Eva|Finance|  3500|  2021-05-20|       350.0|\n|  6|  Frank|     HR|  2800|  2021-06-10|       280.0|\n|  7|  Grace|     IT|  4500|  2021-07-30|       450.0|\n+---+-------+-------+------+------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with a 10% bonus to each employee’s salary.\n",
    "new_column = df.withColumn(\"bonus_salary\",col('salary')*0.10 )\n",
    "new_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c32352-63e9-4394-8b76-5b0df1404d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+------+------------+----------+\n| id|   name|dept|salary|joining_date|dense_rank|\n+---+-------+----+------+------------+----------+\n|  3|Charlie|  IT|  5000|  2021-03-01|         2|\n+---+-------+----+------+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find the 2nd highest salary in the company.\n",
    "window_specific = Window.orderBy(col(\"salary\").desc())\n",
    "highest_salry = df.withColumn(\"dense_rank\", dense_rank().over(window_specific))\n",
    "# highest_salry.show()\n",
    "second_hight= highest_salry.filter(\"dense_rank = 2\")\n",
    "second_hight.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fd29a3-6774-4920-981a-f78499808d73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n|   dept|count|\n+-------+-----+\n|     HR|    2|\n|     IT|    3|\n|Finance|    2|\n+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Count employees per department.\n",
    "df.groupBy('dept').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c6da2da-ab1a-4969-a027-3c425244b3be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n|   dept|avg_salary|\n+-------+----------+\n|     HR|    2900.0|\n|     IT|    4500.0|\n|Finance|    4750.0|\n+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Find average salary per department.\n",
    "\n",
    "df.groupBy('dept').agg(avg('salary').alias(\"avg_salary\")).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Batch18-Pyspark Assignment-2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}